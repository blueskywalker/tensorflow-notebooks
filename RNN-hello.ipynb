{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-14T23:58:58.804044Z",
     "start_time": "2024-01-14T23:58:58.800437Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "data = \"hello\"\n",
    "char_set = sorted(list(set(data)))\n",
    "def one_hot_encode(char):\n",
    "    return np.array([int(char == char_set[i]) for i in range(len(char_set))])\n",
    "\n",
    "print(one_hot_encode(\"h\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:20:43.380051Z",
     "start_time": "2024-01-15T00:20:43.376417Z"
    }
   },
   "id": "58d67a6ed60f6ecc",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1.nn as nn "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a0d0086417590a7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[0.06630785 0.09286073]]], shape=(1, 1, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/3qmgzxs52t570_hcxwnccnl40000gq/T/ipykernel_89142/2185952186.py:1: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = nn.rnn_cell.BasicLSTMCell(2)\n"
     ]
    }
   ],
   "source": [
    "cell = nn.rnn_cell.BasicLSTMCell(2)\n",
    "x_data = np.array([[[0,1,0,0]]], dtype=np.float32)\n",
    "outputs, _states = nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "print(outputs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:22:52.665554Z",
     "start_time": "2024-01-15T00:22:52.643809Z"
    }
   },
   "id": "3da41578176faafb",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 5, 4), dtype=float32, numpy=\narray([[[0., 1., 0., 0.],\n        [1., 0., 0., 0.],\n        [0., 0., 1., 0.],\n        [0., 0., 1., 0.],\n        [0., 0., 0., 1.]]], dtype=float32)>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_input(source):\n",
    "    return np.array([one_hot_encode(char) for char in source], dtype=np.float32)\n",
    "\n",
    "tf.expand_dims(generate_input(\"hello\"), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:25:32.714331Z",
     "start_time": "2024-01-15T00:25:32.711030Z"
    }
   },
   "id": "f439c6fe69da5649",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.07471338  0.09115146]\n",
      "  [ 0.15714878  0.13329597]\n",
      "  [ 0.20319963 -0.00927099]\n",
      "  [ 0.2341277  -0.17273603]\n",
      "  [ 0.17550129 -0.12324703]]], shape=(1, 5, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/3qmgzxs52t570_hcxwnccnl40000gq/T/ipykernel_89142/325307102.py:3: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = nn.rnn_cell.BasicLSTMCell(hidden_size)\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 2\n",
    "sequence_length = len(\"hello\")\n",
    "cell = nn.rnn_cell.BasicLSTMCell(hidden_size)\n",
    "x_data = tf.expand_dims(generate_input(\"hello\"), axis=0)\n",
    "outputs, _states = nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "print(outputs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:29:34.114775Z",
     "start_time": "2024-01-15T00:29:34.105564Z"
    }
   },
   "id": "f9508130bf217906",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 7, 5), dtype=float32, numpy=\narray([[[0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0.],\n        [0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1.]]], dtype=float32)>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"hihello\"\n",
    "char_set = sorted(list(set(data)))\n",
    "\n",
    "def one_hot_encode(char):\n",
    "    return np.array([int(char == char_set[i]) for i in range(len(char_set))])\n",
    "\n",
    "def generate_input(source):\n",
    "    return np.array([one_hot_encode(char) for char in source], dtype=np.float32)\n",
    "\n",
    "tf.expand_dims(generate_input(\"hihello\"), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:37:07.482096Z",
     "start_time": "2024-01-15T00:37:07.476703Z"
    }
   },
   "id": "9e559dccc458fc56",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "389e5d574627e8b1"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c27ee7b3e217263a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1:  0.5130153 Loss2:  0.3711007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerrykim/workspace/deep-learning/tensorflow/venv/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "y_data = tf.constant([[1,1,1]])\n",
    "prediction1 = tf.constant([[[0.3,0.7],[0.3,0.7],[0.3,0.7]]], dtype=tf.float32)\n",
    "prediction2 = tf.constant([[[0.1, 0.9],[0.1, 0.9],[0.1, 0.9]]], dtype=tf.float32)\n",
    "\n",
    "weights = tf.constant([[1,1,1]], dtype=tf.float32)\n",
    "\n",
    "sequence_loss1 = tfa.seq2seq.sequence_loss(prediction1, y_data, weights)\n",
    "sequence_loss2 = tfa.seq2seq.sequence_loss(prediction2, y_data, weights)\n",
    "print(\"Loss1: \", sequence_loss1.numpy()\n",
    ", \"Loss2: \", sequence_loss2.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T03:43:07.819531Z",
     "start_time": "2024-01-15T03:43:07.765017Z"
    }
   },
   "id": "61a36f73986360ed",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.01321007  0.04635428  0.07408268 -0.02713791 -0.02591958\n",
      "   -0.04962373 -0.0792703  -0.03478202 -0.04754604  0.01435794]\n",
      "  [-0.04658528  0.00550043  0.04283317 -0.07995345 -0.05623904\n",
      "   -0.08495228  0.01850726 -0.04871839 -0.09588163  0.06942505]\n",
      "  [ 0.03590014  0.01109139 -0.00804782  0.00051419  0.03101098\n",
      "   -0.03008408 -0.05675561  0.03510022 -0.10037988  0.00074052]\n",
      "  [ 0.03984265  0.05516316  0.07211756 -0.03327267  0.00567346\n",
      "   -0.07272393 -0.11708515 -0.00935009 -0.1341738   0.00994467]\n",
      "  [-0.02587041  0.08274609  0.0717361  -0.07030126  0.02432912\n",
      "   -0.09829973 -0.08974345  0.01033309 -0.08339881  0.04034544]\n",
      "  [-0.05861273  0.09977069  0.06624457 -0.002056    0.03907097\n",
      "   -0.09859533  0.00041083  0.03706269 -0.11410582 -0.07426126]\n",
      "  [ 0.02469691  0.02738264  0.09286562 -0.02815435 -0.02580206\n",
      "    0.00609496  0.05143228 -0.02521962 -0.08076978 -0.11420061]\n",
      "  [ 0.03080313  0.06444271  0.13317785 -0.05494668 -0.04345125\n",
      "   -0.03083249 -0.04363571 -0.04056849 -0.10153189 -0.08317116]\n",
      "  [-0.01602767  0.02639116  0.16968232 -0.07478198  0.06320474\n",
      "    0.00210273 -0.06807273  0.04519903 -0.03925364 -0.04947639]\n",
      "  [ 0.01953777  0.01099164  0.1110227  -0.12760662  0.0689483\n",
      "   -0.04985727 -0.0015999   0.0207623   0.01661072  0.01745015]\n",
      "  [-0.01543579 -0.03872384  0.07211041 -0.03337197  0.1172419\n",
      "    0.01464288 -0.05216252  0.00059817 -0.04012287 -0.01063362]\n",
      "  [ 0.07109267 -0.02398051  0.01612004 -0.07362375  0.06789766\n",
      "   -0.05504216  0.01828322 -0.03856249 -0.03413333  0.00558361]\n",
      "  [ 0.07504337  0.03052885  0.09199985 -0.08575755  0.02867061\n",
      "   -0.09274451 -0.06549583 -0.06029308 -0.07548651  0.02522978]\n",
      "  [ 0.01049012  0.06285033  0.08793744 -0.09881154  0.0389348\n",
      "   -0.10880873 -0.05337984 -0.02930347 -0.04223795  0.05484937]\n",
      "  [-0.03487572  0.08815739  0.07988875 -0.02296694  0.04902571\n",
      "   -0.105005    0.02613052  0.0121248  -0.08207387 -0.05589733]]], shape=(1, 15, 10), dtype=float32)\n",
      "step:  0  loss:  2.2981215\n",
      "Prediction str:  fy faaffffn ffa\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1.nn as nn\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "\n",
    "tf.random.set_seed(777)  # reproducibility\n",
    "sample = \" if you want you\"\n",
    "charset = sorted(list(set(sample)))  # index -> char\n",
    "char2idx = {c: i for i, c in enumerate(charset)}  # char -> index\n",
    "\n",
    "# hyper parameters\n",
    "dic_size = len(char2idx)  # RNN input size (one hot size)\n",
    "hidden_size = len(char2idx)  # RNN output size\n",
    "num_classes = len(char2idx)  # final output size (RNN or softmax, etc.)\n",
    "batch_size = 1  # one sample data, one batch\n",
    "sequence_length = len(sample) - 1  # number of lstm rollings (unit #)\n",
    "learning_rate = 0.1\n",
    "\n",
    "sample_idx = [char2idx[c] for c in sample]  # char to index\n",
    "# x_data = [sample_idx[:-1]]  # X data sample (0 ~ n-1) hello: hell\n",
    "# y_data = [sample_idx[1:]]   # Y label sample (1 ~ n) hello: ello\n",
    "\n",
    "def one_hot_encode(char):\n",
    "    return np.array([int(char == charset[i]) for i in range(len(charset))])\n",
    "\n",
    "def generate_input(source):\n",
    "    return np.array([one_hot_encode(char) for char in source], dtype=np.float32)\n",
    "\n",
    "x_data = tf.expand_dims(generate_input(sample[:-1]), axis=0)\n",
    "y_data = tf.expand_dims(generate_input(sample[1:]), axis=0)\n",
    "\n",
    "cell = keras.layers.LSTMCell(hidden_size)\n",
    "initial_state = cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
    "# print(initial_state)\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "#print(weights)\n",
    "for i in range(20):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs, _states = nn.dynamic_rnn(cell, x_data, initial_state=initial_state, dtype=tf.float32)\n",
    "        # print(outputs)\n",
    "        sequence_loss = tfa.seq2seq.sequence_loss(logits=outputs, targets=y_data, weights=weights)\n",
    "        mean_loss = tf.reduce_mean(sequence_loss)\n",
    "        print(\"step: \", i, \" loss: \", mean_loss.numpy())\n",
    "    grads = tape.gradient(mean_loss, cell.trainable_variables)\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "    optimizer.apply_gradients(zip(grads, cell.trainable_variables))\n",
    "    prediction = tf.argmax(outputs, axis=2)    \n",
    "    result_str = [charset[c] for c in np.squeeze(prediction)]\n",
    "    # print(\"prediction: \", prediction.numpy())\n",
    "    print(\"Prediction str: \", ''.join(result_str))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:38:59.164984Z",
     "start_time": "2024-01-15T06:38:59.109378Z"
    }
   },
   "id": "fc38a55c452db1f7",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(184, 27), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(184, 27), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'lstm_cell_30' (type LSTMCell).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [184,7,108] vs. [184,108] [Op:AddV2] name: \n\nCall arguments received by layer 'lstm_cell_30' (type LSTMCell):\n  • inputs=tf.Tensor(shape=(184, 7, 27), dtype=float32)\n  • states=['tf.Tensor(shape=(184, 27), dtype=float32)', 'tf.Tensor(shape=(184, 27), dtype=float32)']\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[73], line 55\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mGradientTape() \u001B[38;5;28;01mas\u001B[39;00m tape:\n\u001B[0;32m---> 55\u001B[0m         outputs, _states \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdynamic_rnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcell\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m        \n\u001B[1;32m     56\u001B[0m         \u001B[38;5;66;03m# print(outputs)\u001B[39;00m\n\u001B[1;32m     57\u001B[0m         sequence_loss \u001B[38;5;241m=\u001B[39m tfa\u001B[38;5;241m.\u001B[39mseq2seq\u001B[38;5;241m.\u001B[39msequence_loss(logits\u001B[38;5;241m=\u001B[39moutputs, targets\u001B[38;5;241m=\u001B[39mY_data, weights\u001B[38;5;241m=\u001B[39mweights)\n",
      "File \u001B[0;32m~/workspace/deep-learning/tensorflow/venv/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:383\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecated_wrapper.<locals>.new_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    375\u001B[0m         _PRINTED_WARNING[\u001B[38;5;28mcls\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    376\u001B[0m     _log_deprecation(\n\u001B[1;32m    377\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFrom \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m (from \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m) is deprecated and will be removed \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    378\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInstructions for updating:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m, _call_location(),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    381\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124min a future version\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m date \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m date),\n\u001B[1;32m    382\u001B[0m         instructions)\n\u001B[0;32m--> 383\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/deep-learning/tensorflow/venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/workspace/deep-learning/tensorflow/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Exception encountered when calling layer 'lstm_cell_30' (type LSTMCell).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [184,7,108] vs. [184,108] [Op:AddV2] name: \n\nCall arguments received by layer 'lstm_cell_30' (type LSTMCell):\n  • inputs=tf.Tensor(shape=(184, 7, 27), dtype=float32)\n  • states=['tf.Tensor(shape=(184, 27), dtype=float32)', 'tf.Tensor(shape=(184, 27), dtype=float32)']\n  • training=None"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1.nn as nn\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "\n",
    "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
    "            \"collect wood and don't assign them tasks and work, but rather \"\n",
    "            \"teach them to long for the endless immensity of the sea. - Antoine \")\n",
    "\n",
    "\n",
    "char_set = sorted(list(set(sentence)))\n",
    "char2idx = {c: i for i, c in enumerate(char_set)}  # char -> index\n",
    "\n",
    "def one_hot_encode(char):\n",
    "    return np.array([int(char == char_set[i]) for i in range(len(char_set))])\n",
    "\n",
    "def generate_code(source):\n",
    "    return tf.expand_dims(np.array([one_hot_encode(char) for char in source], dtype=np.float32), axis=0)\n",
    "\n",
    "sequence_length = 7\n",
    "data_dim = len(char_set)\n",
    "hidden_size = len(char_set)\n",
    "num_classes = len(char_set)\n",
    "\n",
    "dataX = []\n",
    "dataY = []\n",
    "tf.random.set_seed(777)\n",
    "\n",
    "for i in range(0, len(sentence) - sequence_length):\n",
    "    x_str = sentence[i:i + sequence_length]\n",
    "    y_str = sentence[i + 1: i + sequence_length + 1]\n",
    "    # print(i, x_str, '->', y_str)\n",
    "\n",
    "    # x = [char2idx[c] for c in x_str]  # x str to index\n",
    "    # y = [char2idx[c] for c in y_str]  # y str to index\n",
    "    \n",
    "    dataX.append(generate_code(x_str))\n",
    "    dataY.append(generate_code(y_str))\n",
    "\n",
    "X_data = np.array(dataX)\n",
    "Y_data = np.array(dataY)\n",
    "\n",
    "\n",
    "# print(Y_data.shape)\n",
    "batch_size = len(X_data)\n",
    "# print(batch_size)\n",
    "cell = keras.layers.LSTMCell(hidden_size)\n",
    "initial_state = cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
    "print(initial_state)\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "\n",
    "for i in range(1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs, _states = nn.dynamic_rnn(cell, X_data, initial_state=initial_state, dtype=tf.float32)        \n",
    "        # print(outputs)\n",
    "        sequence_loss = tfa.seq2seq.sequence_loss(logits=outputs, targets=Y_data, weights=weights)\n",
    "        mean_loss = tf.reduce_mean(sequence_loss)\n",
    "        print(\"step: \", i, \" loss: \",sequence_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T02:12:17.570108Z",
     "start_time": "2024-01-16T02:12:17.503864Z"
    }
   },
   "id": "a3f5193d32e92391",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f1a4cbb4a96c301d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
